# CrossVoice: Crosslingual Prosody Preserving Cascade-S2ST using Transfer Learning


This repository contains the code for our work titled `CrossVoice: Crosslingual Prosody Preserving Cascade-S2ST using Transfer Learning`, accepted at the **Tiny Track of ICLR'24**. The following scripts contain the code for the CrossVoice Pipeline for various hardware settings:

*  `crossvoice_fastwhisper_cpu.py`: CPU Implementation using FastWhisper.
*  `crossvoice_whisper_gpu.py`: GPU Implementation using Whisper/Medium.

## Proposed Pipeline
<img width="885" alt="Screenshot 2024-10-07 at 1 01 23 PM" src="https://github.com/user-attachments/assets/028fe440-e9cf-4583-926b-3469a076e682">

It is a comprehensive pipeline for converting speech in one language to speech in another language, leveraging various libraries and APIs for speech recognition, translation, and text-to-speech synthesis. The pipeline includes noise reduction, automatic speech recognition (ASR) using a Whisper model, translation via Google Translate, and finally, text-to-speech (TTS) output in the target language with parallel prosody-transfer via transfer learning based Voice Cloning (VC)

### Features

- **Noise Reduction:** Utilizes the `noisereduce` library to reduce background noise from the input audio file.
- **Speech Recognition:** Employs the `Whisper` model for accurate and efficient speech-to-text conversion and `Flash-Attention` for reducing transcription time.
- **Translation:** Leverages the `googletrans` library to translate the recognized text into the target language.
- **Text-to-Speech:** Uses the `TTS` library from Coqui TTS for generating speech from the translated text in the target language.
- **Prosody Transfer:** Speaker embeddings are extracted from the source audio file and used by a voice cloning module to transfer the prosody from the source audio to the translated audio.

### Usage

* For loading the dependencies, the given yaml file can be used through the following command:
```bash
conda env create -f Environment.yml
```  

1. **Set Up Language Mappings:** The script starts with dictionaries mapping language names to their respective ISO codes and Google Translate codes.

2. **Translation Function:** A function `translate_text` is defined to translate text using Google Translate.

3. **Whisper Model Loading:** The `load_whisper_model` function initializes the Whisper model based on the specified model size, device, and compute type.

4. **Main Pipeline:** The `if __name__ == "__main__"` block guides the script's execution flow, including user input for target language, audio preprocessing for silence removal, speech recognition, translation, and finally, speech synthesis in the target language.

5. **Preprocessing:** Audio is preprocessed by removing silence sections to improve the efficiency and accuracy of speech recognition.

6. **Speech Recognition:** The processed audio is then transcribed into text using the Whisper model.

7. **Translation:** The recognized speech is translated into the target language.

8. **Speech Synthesis:** The translated text is converted back to speech using a TTS model corresponding to the target language.

To run the script, execute it in a Python environment where all dependencies are installed. You will need to provide the path to the input audio file and choose the target language for translation.

## MoS Results
<img width="1397" alt="Screenshot 2024-10-07 at 1 41 48 PM" src="https://github.com/user-attachments/assets/ceb3f32b-9c45-4ec0-816b-98101b8877e7">

We have also provided sample voice clips generated by CrossVoice divided into the following sets:
1. `librispeech-noisy`: Noisy English file translated into Spanish, French, German, Tamil and Hindi using CrossVoice and a vanilla TTS.
2. `custom-clip`: A custom recorded clip with Indian accent in English translated to Gujarati, Marathi, Tamil and Hindi through CrossVoice.
3. `custom-clip-two`: A custom recorded clip in Hindi translated to Gujarati, Marathi and Tamil through CrossVoice.
4. `VoxPopuli`: Spanish, French and German source files were taken from the VoxPopuli dataset and translated into English.

### Citation

If found helpful, please cite our work using
```bibtex
@inproceedings{
hira2024crossvoice,
title={CrossVoice: Crosslingual Prosody Preserving Cascade-S2{ST} using Transfer Learning},
author={Medha Hira and Arnav Goel and Anubha Gupta},
booktitle={The Second Tiny Papers Track at ICLR 2024},
year={2024},
url={https://openreview.net/forum?id=zEdBzTxXHl}
}
```
